{"class":"org.apache.spark.ml.feature.RegexTokenizer","timestamp":1575842356912,"sparkVersion":"2.4.4","uid":"regexTok_84811efeaa2d","paramMap":{"gaps":true,"pattern":"\\W+","inputCol":"text","outputCol":"tokens"},"defaultParamMap":{"toLowercase":true,"gaps":true,"pattern":"\\s+","minTokenLength":1,"outputCol":"regexTok_84811efeaa2d__output"}}
